{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Создание датасета**\n",
        "P.s. Только при первом запуске"
      ],
      "metadata": {
        "id": "noKAAn8vDXN-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXohIZc9lnan"
      },
      "outputs": [],
      "source": [
        "run_gnuplot = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iyoq8cLTzLJ_",
        "outputId": "4dfe63e0-4d25-4de5-f96c-06e683a654a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifaUUT4S0XzB",
        "outputId": "150e9943-f97b-4f1c-e7b7-13625c2b9736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'1_AlexNet_optim=Adam_bs=16_params=D_tp_tb_size=64.pth'     gnuplot\t        __pycache__\n",
            "'1_AlexNet_optim=Adam_bs=16_params=V_D_tp_tb_size=64.pth'   LICENSE\t        README.md\n",
            " Data\t\t\t\t\t\t\t    mean_disp.json      samples_celeba_attn\n",
            " Data299\t\t\t\t\t\t    model_64.py         spectral.py\n",
            " draw_phases.py\t\t\t\t\t\t    model.py\t        Test\n",
            " file_to_phase.py\t\t\t\t\t    models\t        test_img\n",
            " filter.py\t\t\t\t\t\t    norm_denorm.py      utils.py\n",
            " fit_models.ipynb\t\t\t\t\t    predict_params.py   ZipData\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Chemistry-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlBVg2aZJKBe"
      },
      "outputs": [],
      "source": [
        "if run_gnuplot:\n",
        "    !sudo apt-get -y install gnuplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9gDJPOwIvYi"
      },
      "outputs": [],
      "source": [
        "#!ls /usr/bin/*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYx4GRv_MFMF"
      },
      "outputs": [],
      "source": [
        "if run_gnuplot:\n",
        "    %cd /content/drive/MyDrive/Chemistry-main/Data/\n",
        "    !pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rM4SzXfQGrFh"
      },
      "outputs": [],
      "source": [
        "if run_gnuplot:\n",
        "    !bash /content/drive/MyDrive/Chemistry-main/Data/really_all_region.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ssrTfCykva8"
      },
      "outputs": [],
      "source": [
        "if run_gnuplot:\n",
        "    import os\n",
        "    for file_name in os.listdir('/content/drive/MyDrive/Chemistry-main/Data/'):\n",
        "        # some filter\n",
        "        if 'result' not in file_name or 'contour' not in file_name:\n",
        "            continue\n",
        "        print('rename', file_name)\n",
        "        new_file_name = file_name.replace('.csv', '_')\n",
        "        os.rename(file_name, new_file_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Инициализация**"
      ],
      "metadata": {
        "id": "uW-zkuE5DseO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrnVcZbVhFwq",
        "outputId": "af19120e-8623-4c45-a768-94f893ed2417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Chemistry-main\n",
            "/content/drive/MyDrive/Chemistry-main\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Chemistry-main/\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKtQaqY2hnl3"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from utils import seed, get_train_dataloader, get_test_dataloader, model_to_log, split_x_train, load_data_phase, read_phase_file\n",
        "from model import get_model, load_model\n",
        "from norm_denorm import calculate_mean_disp, norm, denorm\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOD_Y29nh1FB"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "lr = 1e-4\n",
        "epochs = 200\n",
        "batch_size = 31\n",
        "step_size = 20\n",
        "gamma = 0.99\n",
        "# parameters to be predicted\n",
        "params = ['D', 'tp', 'tb']  # 'V', 'D', 'tp', 'tb'\n",
        "\n",
        "# path to folder and training set\n",
        "train_folder = '/content/drive/MyDrive/Chemistry-main/Data'\n",
        "test_folder = '/content/drive/MyDrive/Chemistry-main/Test'\n",
        "# file name to save mean and variance for normalization\n",
        "mean_disp_file = 'mean_disp.json'\n",
        "\n",
        "# phase pattern size\n",
        "phase_size = (64, 64)\n",
        "\n",
        "config = {\n",
        "    \"lr\": lr,\n",
        "    \"epochs\": epochs,\n",
        "    \"bs\": batch_size,\n",
        "    \"sched\": 'StepLR',\n",
        "    \"sched_ss\": step_size,\n",
        "    \"sched_g\": gamma,\n",
        "    \"params\": '_'.join(params),\n",
        "    \"optim\": 'Adam',\n",
        "    \"size\": phase_size[0],\n",
        "}\n",
        "important_keys = ['optim', 'bs', 'params']\n",
        "config['exp_name'] = 'InceptionResnetV1_' + '_'.join(map(lambda key: f'{key}={config[key]}', important_keys))\n",
        "model_file_name = config['exp_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vRX4XuGiLiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0066c21a-1da8-44f8-e9b3-e0257a29b28c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.18252184 0.52264665 0.80569206] [0.00456303 0.00492078 0.00120417]\n"
          ]
        }
      ],
      "source": [
        "from norm_denorm import dump_mean_disp\n",
        "\n",
        "mean, dispersion = calculate_mean_disp(train_folder, params)\n",
        "print(mean, dispersion)\n",
        "\n",
        "# maintaining the average and variance of usage with an already trained network\n",
        "# dump_mean_disp(mean_disp_file, mean, dispersion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rShuIwPBqMCb"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = load_data_phase(train_folder, params, phase_size)\n",
        "y_train = norm(y_train, mean, dispersion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yCT-pYX94RH"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_val, y_val = map(lambda x: torch.tensor(x, dtype=torch.float, device=device), split_x_train(x_train, y_train, 31))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataloader = get_test_dataloader(x_val, y_val, batch_size)"
      ],
      "metadata": {
        "id": "LbfmbqEvDFgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILyV6A1mrID5"
      },
      "outputs": [],
      "source": [
        "train_dataloader = get_train_dataloader(x_train, y_train, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eG5UIBaEyb9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from torchvision.utils import save_image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# импорт моделей, оставить что-то одно\n",
        "from model_InceptionResnetV1 import Autoencoder # параметр device, по умалчанию None\n",
        "from model_SAA import Autoencoder # параметр attn=True/False, включает или выключает слои самовнимания, по умалчанию True\n",
        "from model_resnet import Autoencoder # параметр net, по умалчанию net=\"resnet50\". Возможные варианты: 'resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152'"
      ],
      "metadata": {
        "id": "eJXjZ5wPEHCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Обучение**\n",
        "\n",
        "Переменная load_prev_model говорит о том, нужно ли продолжать обучение со старыми весами, или начать с начала.\n",
        "\n",
        "В training_model выбираем что обучаем, автоэнкодер(AE) или модель предсказывающаю параметры по автоэнкодеру(param_AE)."
      ],
      "metadata": {
        "id": "XnAGHS9CEp2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_prev_model = False\n",
        "training_model = \"AE\" # [\"AE\", \"param_AE\", \"param\"]"
      ],
      "metadata": {
        "id": "goNTjBs2GhNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZisNVys45rH"
      },
      "outputs": [],
      "source": [
        "# Для обучение предсказания параметров по обученному автоэнкодеру\n",
        "def train_epoch_param(model, encoder, loss, optimizer, dataloader, do_train):\n",
        "    running_loss = 0.\n",
        "\n",
        "    # Iterate over data.\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward and backward\n",
        "        with torch.set_grad_enabled(do_train):\n",
        "            # 4\n",
        "            # preds, _, _ = encoder(inputs)\n",
        "            # 3\n",
        "            # preds = encoder(inputs)\n",
        "            #\n",
        "            _, z = encoder(inputs)\n",
        "            # print(preds.size())\n",
        "            preds = model(z)\n",
        "            loss_value = loss(preds, targets)\n",
        "\n",
        "            # backward + optimize only if in training phase\n",
        "            if do_train:\n",
        "                loss_value.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss_value.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "def train_model_param(model, encoder, loss, optimizer, scheduler, train_dataloader, val_dataloader, num_epochs, config, start_epoch=-1, prev_loss=None):\n",
        "    if prev_loss:\n",
        "      best_val_loss = prev_loss\n",
        "    else:\n",
        "      best_val_loss = math.inf\n",
        "    save__original = True\n",
        "    for epoch in range(start_epoch+1, num_epochs):\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                dataloader = train_dataloader\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                dataloader = val_dataloader\n",
        "                model.eval()  # Set model to evaluate mode\n",
        "\n",
        "            epoch_loss = train_epoch_param(model, encoder, loss, optimizer, dataloader, phase == 'train')\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            print('loss', epoch_loss, 'epoch', epoch)\n",
        "\n",
        "            if phase == 'val' and best_val_loss > epoch_loss:\n",
        "                print('New best val loss', epoch_loss, 'epoch', epoch)\n",
        "                best_val_loss = epoch_loss\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': epoch_loss,\n",
        "                    'model_name': config['exp_name']\n",
        "                }, f'./models/param_{config[\"exp_name\"]}.pth')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Для обучение Автоэнкодера\n",
        "def train_epoch(model, loss, optimizer, dataloader, do_train):\n",
        "    running_loss = 0.\n",
        "\n",
        "    # Iterate over data.\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward and backward\n",
        "        with torch.set_grad_enabled(do_train):\n",
        "            preds, _ = model(inputs)\n",
        "            loss_value = loss(preds, inputs)\n",
        "\n",
        "            # backward + optimize only if in training phase\n",
        "            if do_train:\n",
        "                loss_value.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        # statistics\n",
        "        running_loss += loss_value.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "def train_model(model, loss, optimizer, scheduler, train_dataloader, val_dataloader, num_epochs, config, start_epoch=-1, prev_loss=None):\n",
        "    if prev_loss:\n",
        "      best_val_loss = prev_loss\n",
        "    else:\n",
        "      best_val_loss = math.inf\n",
        "    save__original = True\n",
        "    for epoch in range(start_epoch+1, num_epochs):\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                dataloader = train_dataloader\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                dataloader = val_dataloader\n",
        "                model.eval()  # Set model to evaluate mode\n",
        "\n",
        "            epoch_loss = train_epoch(model, loss, optimizer, dataloader, phase == 'train')\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            print('loss', epoch_loss, 'epoch', epoch)\n",
        "\n",
        "            if phase == 'val' and best_val_loss > epoch_loss:\n",
        "                print('New best val loss', epoch_loss, 'epoch', epoch)\n",
        "                best_val_loss = epoch_loss\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': epoch_loss,\n",
        "                    'model_name': config['exp_name']\n",
        "                }, f'./models/{config[\"exp_name\"]}.pth')\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "zH2of41VFRuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if training_model == \"param_AE\":\n",
        "    # загрузка весов автоэнкодера\n",
        "    autoencoder_state_dict = torch.load(f'./models/{config[\"exp_name\"]}.pth')['model_state_dict']\n",
        "    AE = Autoencoder()\n",
        "    AE.load_state_dict(autoencoder_state_dict)\n",
        "    AE.eval()\n",
        "\n",
        "    del autoencoder_state_dict"
      ],
      "metadata": {
        "id": "aIRiYAP1o9Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if training_model == \"param_AE\":\n",
        "    model = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1792, 512),\n",
        "            # nn.Dropout(p=0.01),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, len(params))\n",
        "        )\n",
        "\n",
        "    # loss_func = torch.nn.L1Loss()\n",
        "    loss_func = torch.nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
      ],
      "metadata": {
        "id": "T84CYCKABUH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if training_model == \"param_AE\":\n",
        "    save = torch.load(f'./models/param_{config[\"exp_name\"]}.pth')\n",
        "    if load_prev_model:\n",
        "      start_epoch = save['epoch']\n",
        "      start_loss = save['loss']\n",
        "    else:\n",
        "      start_epoch = -1\n",
        "      start_loss = None\n",
        "\n",
        "    print(start_epoch, start_loss)\n",
        "\n",
        "    if load_prev_model:\n",
        "    model.load_state_dict(save['model_state_dict'])\n",
        "    optimizer.load_state_dict(save['optimizer_state_dict'])\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "gRM87X8yKMXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ucaoQaC86PY"
      },
      "outputs": [],
      "source": [
        "if training_model == \"param_AE\":\n",
        "    model = train_model_param(model, AE, loss_func, optimizer, scheduler, train_dataloader, val_dataloader, epochs, config, start_epoch, start_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if training_model == \"AE\":\n",
        "    # не забываем указать параметры, в зависимости от архитектуры\n",
        "    model = Autoencoder()\n",
        "\n",
        "    # loss_func = torch.nn.L1Loss()\n",
        "    loss_func = torch.nn.MSELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
      ],
      "metadata": {
        "id": "lhodRJ9VKxtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if training_model == \"AE\":"
      ],
      "metadata": {
        "id": "0GreEZ0aLE9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvzZapqvrdhy"
      },
      "outputs": [],
      "source": [
        "if training_model == \"AE\":\n",
        "    if load_prev_model:\n",
        "      save = torch.load(f'./models/{config[\"exp_name\"]}.pth')\n",
        "      model.load_state_dict(save['model_state_dict'])\n",
        "      optimizer.load_state_dict(save['optimizer_state_dict'])\n",
        "      model.train()\n",
        "      start_epoch = save['epoch']\n",
        "      prev_loss = save['loss']\n",
        "      print('loss ', prev_loss)\n",
        "      print('start_epoch ', start_epoch)\n",
        "      del save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7MX-1NVOrlNB"
      },
      "outputs": [],
      "source": [
        "if training_model == \"AE\":\n",
        "    if load_prev_model:\n",
        "      model = train_model(model, loss_func, optimizer, scheduler, train_dataloader, val_dataloader, epochs, config, start_epoch, prev_loss)\n",
        "    else:\n",
        "      model = train_model(model, loss_func, optimizer, scheduler,train_dataloader, val_dataloader, epochs, config)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Тестирование и метрики**"
      ],
      "metadata": {
        "id": "cfCAy2rvGQKS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCKg2Nr0CFg8"
      },
      "outputs": [],
      "source": [
        "x_test, y_test = load_data_phase(test_folder, params, phase_size)\n",
        "y_test = norm(y_test, mean, dispersion)\n",
        "x_test, y_test = map(lambda x: torch.tensor(x, dtype=torch.float, device=device), (x_test, y_test))\n",
        "test_dataloader = get_train_dataloader(x_test, y_test, 31)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_state_dict = torch.load(f'./models/{config[\"exp_name\"]}.pth')['model_state_dict']\n",
        "AE = Autoencoder()\n",
        "AE.load_state_dict(autoencoder_state_dict)\n",
        "AE.eval()\n",
        "\n",
        "del autoencoder_state_dict"
      ],
      "metadata": {
        "id": "bShY_CbuGXcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-XSV_h2CkJk"
      },
      "outputs": [],
      "source": [
        "best_model = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(1792, 512),\n",
        "        # nn.Dropout(p=0.01),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 32),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(32, len(params))\n",
        "    )\n",
        "best_model.load_state_dict(torch.load(f'./models/{config[\"exp_name\"]}.pth')['model_state_dict'])\n",
        "best_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pk4KPuyUAM7"
      },
      "outputs": [],
      "source": [
        "# сохранение оригинальной и созданой AE фазовой диаграммы\n",
        "for inputs, targets in test_dataloader:\n",
        "  save_image(inputs, os.path.join('./test_img', f'original_AE_IRN1.png'))\n",
        "  save_image(AE(inputs)[0], os.path.join('./test_img', 'fake_AE_IRN1.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvbUOny5Gx9Q"
      },
      "outputs": [],
      "source": [
        "FP, FN, TP, TN = 0, 0, 0, 0\n",
        "for inputs, targets in test_dataloader:\n",
        "    fake, z = AE(inputs)\n",
        "    for i in range(len(inputs)):\n",
        "        for j in range(len(inputs[i])):\n",
        "            for k1 in range(len(inputs[i][j])):\n",
        "                for k2 in range(len(inputs[i][j][k1])):\n",
        "                    predicted = round(float(fake[i][j][k1][k2]))\n",
        "                    actual = inputs[i][j][k1][k2]\n",
        "                    if predicted == 1 and actual == 1:\n",
        "                        TP += 1\n",
        "                    elif predicted == 0 and actual == 0:\n",
        "                        TN += 1\n",
        "                    elif actual == 1 and predicted == 0:\n",
        "                        FN += 1\n",
        "                    elif actual == 0 and predicted == 1:\n",
        "                        FP += 1\n",
        "    # print(FP, FN, TP, TN)\n",
        "print(\"f1 =\", 2*TP / (2*TP + FP + FN))\n",
        "print(\"IoU =\", TP / (TP + FP + FN))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vDcGHGuKkXX"
      },
      "outputs": [],
      "source": [
        "y_train_result = best_model.forward(AE(x_train)[1]).detach()\n",
        "y_val_result = best_model.forward(AE(x_val)[1]).detach()\n",
        "y_test_result = best_model.forward(AE(x_test)[1]).detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4euePrvribn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "y_train_result_np = np.array(y_train_result)\n",
        "y_val_result_np = y_val_result.cpu().numpy()\n",
        "y_test_result_np = y_test_result.detach().cpu().numpy()\n",
        "\n",
        "y_train_np = y_train.detach().cpu().numpy()\n",
        "y_val_np = y_val.detach().cpu().numpy()\n",
        "y_test_np = y_test.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKh6sVAmrlVG"
      },
      "outputs": [],
      "source": [
        "def add_subplot(fig, train, result, param_index, plot_index, label):\n",
        "\n",
        "    sort = train[:, param_index].argsort(axis=0).reshape((-1,))\n",
        "    ax_train = fig.add_subplot(3, 1, plot_index)\n",
        "    ax_train.set_title(label=label, fontsize=12)\n",
        "    ax_train.set_ylabel(param)\n",
        "    ax_train.set_xlabel('num File')\n",
        "    ax_train.plot(denorm(train[sort], mean, dispersion)[:, param_index], 'go', label='train')\n",
        "    ax_train.plot(denorm(result[sort], mean, dispersion)[:, param_index], 'ro', label='result')\n",
        "    ax_train.legend()\n",
        "\n",
        "def show(param_index, param):\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 12))\n",
        "    fig.suptitle(f'Параметр {param}', fontsize=16)\n",
        "\n",
        "    fig.subplots_adjust(hspace=0.4)\n",
        "\n",
        "    add_subplot(fig, y_train_np, y_train_result_np, param_index, 1, 'Обучающий набор')\n",
        "    add_subplot(fig, y_val_np, y_val_result_np, param_index, 1, 'Валидационный набор')\n",
        "    add_subplot(fig, y_test_np, y_test_result_np, param_index, 2, 'Тестовый набор')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvqVh7kOrmEv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "for param_index, param in enumerate(params):\n",
        "    show(param_index, param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZM7FMniTXLe"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def get_loss(result, real, i):\n",
        "    error_m = torch.nn.MSELoss()(real[:, i], result[:, i]).item()\n",
        "    error_a = torch.nn.L1Loss()(real[:, i], result[:, i]).item()\n",
        "    r2 = r2_score(real[:, i], result[:, i])\n",
        "    return round(error_m, 6), round(error_a, 6), round(r2, 6)\n",
        "\n",
        "def print_errors(i):\n",
        "    train_error_m, train_error_a, r2 = get_loss(y_train_result, y_train, i)\n",
        "    print('train error L1', train_error_a, 'MSE', train_error_m, 'r2', r2)\n",
        "    val_error_m, val_error_a, r2 = get_loss(y_val_result, y_val, i)\n",
        "    print('val error L1', val_error_a, 'MSE', val_error_m, 'r2', r2)\n",
        "    test_error_m, test_error_a, r2 = get_loss(y_test_result, y_test, i)\n",
        "    print('test error L1', test_error_a, 'MSE', test_error_m, 'r2', r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "povX8iQoTXLe"
      },
      "outputs": [],
      "source": [
        "for param_index, param in enumerate(params):\n",
        "    print(param, 'errors')\n",
        "    print_errors(param_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_test, y_test_result)"
      ],
      "metadata": {
        "id": "AkG6q5lgRLXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_val, y_val_result)"
      ],
      "metadata": {
        "id": "CtvHo09iC-pL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "noKAAn8vDXN-"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}